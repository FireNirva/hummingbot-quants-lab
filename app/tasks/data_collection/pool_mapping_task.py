"""
CEXäº¤æ˜“å¯¹åˆ°DEXæ± å­çš„æ˜ å°„ä»»åŠ¡

è¿™ä¸ªä»»åŠ¡è‡ªåŠ¨å°†CEXäº¤æ˜“å¯¹æ˜ å°„åˆ°DEXçš„é«˜æµåŠ¨æ€§æ± å­ï¼Œä½¿ç”¨GeckoTerminal APIæœç´¢ã€‚
"""
import logging
from typing import Dict, Any
from datetime import datetime, timezone

from core.tasks import BaseTask, TaskContext
from core.services.pool_mapping import PoolMappingService
from core.data_paths import data_paths

logging.basicConfig(level=logging.INFO)


class PoolMappingTask(BaseTask):
    """CEXäº¤æ˜“å¯¹åˆ°DEXæ± å­çš„æ˜ å°„ä»»åŠ¡"""
    
    def __init__(self, config):
        super().__init__(config)
        
        # ä»configè¯»å–å‚æ•°ï¼ˆä½¿ç”¨.get()æä¾›é»˜è®¤å€¼ï¼‰
        task_config = self.config.config
        self.network = task_config.get("network", "base")
        self.connector = task_config.get("connector", "gate_io")
        self.trading_pairs = task_config.get("trading_pairs", None)  # None=è‡ªåŠ¨æ£€æµ‹
        self.top_n = task_config.get("top_n", 3)
        self.output_path = task_config.get("output_path", None)  # None=ä½¿ç”¨é»˜è®¤
        
        # æœåŠ¡å®ä¾‹ï¼ˆåœ¨setupä¸­åˆå§‹åŒ–ï¼‰
        self.service = None
        
    async def setup(self, context: TaskContext) -> None:
        """ä»»åŠ¡åˆå§‹åŒ–"""
        await super().setup(context)
        
        # åˆå§‹åŒ–æœåŠ¡
        self.service = PoolMappingService()
        
        # éªŒè¯é…ç½®
        if not self.network:
            raise RuntimeError("network not configured")
        if not self.connector:
            raise RuntimeError("connector not configured")
            
        logging.info(f"Setup completed for {context.task_name}")
        logging.info(f"Network: {self.network}")
        logging.info(f"Connector: {self.connector}")
        logging.info(f"Top N: {self.top_n}")
        
    async def cleanup(self, context: TaskContext, result) -> None:
        """èµ„æºæ¸…ç†"""
        await super().cleanup(context, result)
        logging.info(f"Cleanup completed for {context.task_name}")
        
    async def execute(self, context: TaskContext) -> Dict[str, Any]:
        """ä¸»æ‰§è¡Œé€»è¾‘"""
        start_time = datetime.now(timezone.utc)
        logging.info(f"Starting pool mapping for {self.connector} on {self.network}")
        
        try:
            # 1. è·å–äº¤æ˜“å¯¹åˆ—è¡¨
            if self.trading_pairs:
                pairs = self.trading_pairs
                logging.info(f"Using configured pairs: {len(pairs)} pairs")
            else:
                pairs = self.service.parse_trading_pairs_from_candles(
                    data_paths.candles_dir,
                    connector=self.connector
                )
                logging.info(f"Auto-detected pairs: {len(pairs)} pairs")
            
            if not pairs:
                raise RuntimeError(f"No trading pairs found for {self.connector}")
            
            # 2. æ„å»ºæ˜ å°„
            df, raw_responses = await self.service.build_mapping(
                pairs, self.network, self.connector, self.top_n
            )
            
            # 3. ä¿å­˜ç»“æœï¼ˆä½¿ç”¨data_pathsï¼‰
            self.service.save_raw_responses(raw_responses, self.network)
            output_file = self.service.save_mapping(df, self.network, self.connector)
            
            # 4. ç»Ÿè®¡ä¿¡æ¯
            pools_found = len(df)
            pairs_with_pools = df['trading_pair'].nunique() if not df.empty else 0
            pairs_failed = len(pairs) - pairs_with_pools
            
            # 5. å‡†å¤‡è¿”å›ç»“æœ
            duration = datetime.now(timezone.utc) - start_time
            result = {
                "status": "completed",
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "execution_id": context.execution_id,
                "network": self.network,
                "connector": self.connector,
                "output_file": str(output_file),
                "stats": {
                    "pairs_total": len(pairs),
                    "pairs_with_pools": pairs_with_pools,
                    "pairs_failed": pairs_failed,
                    "pools_found": pools_found,
                    "top_n": self.top_n
                },
                "duration_seconds": duration.total_seconds()
            }
            
            logging.info(f"Pool mapping completed: {result['stats']}")
            return result
            
        except Exception as e:
            logging.error(f"Error executing pool mapping task: {e}")
            raise
    
    async def on_success(self, context: TaskContext, result) -> None:
        """æˆåŠŸå›è°ƒ"""
        stats = result.result_data.get("stats", {})
        logging.info(f"âœ“ PoolMappingTask succeeded in {result.duration_seconds:.2f}s")
        logging.info(f"  - Pairs: {stats.get('pairs_with_pools', 0)}/{stats.get('pairs_total', 0)}")
        logging.info(f"  - Pools found: {stats.get('pools_found', 0)}")
    
    async def on_failure(self, context: TaskContext, result) -> None:
        """å¤±è´¥å›è°ƒ"""
        logging.error(f"âœ— PoolMappingTask failed: {result.error_message}")
        logging.error(f"  Execution ID: {context.execution_id}")
    
    async def on_retry(self, context: TaskContext, attempt: int, error: Exception) -> None:
        """é‡è¯•å›è°ƒ"""
        logging.warning(f"ğŸ”„ PoolMappingTask retry attempt {attempt}: {error}")

