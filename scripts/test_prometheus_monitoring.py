#!/usr/bin/env python3
"""
Prometheusç›‘æ§æµ‹è¯•è„šæœ¬

æµ‹è¯•æŒ‡æ ‡æ”¶é›†å’ŒHTTPå¯¼å‡ºåŠŸèƒ½ã€‚

Usage:
    python scripts/test_prometheus_monitoring.py
"""

import time
import logging
import random
from core.monitoring.metrics import get_metrics
from core.monitoring.exporter import get_exporter

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def simulate_data_collection():
    """æ¨¡æ‹Ÿæ•°æ®æ”¶é›†è¿‡ç¨‹"""
    
    # è·å–æŒ‡æ ‡å®ä¾‹
    metrics = get_metrics()
    
    # è·å–å¹¶å¯åŠ¨å¯¼å‡ºå™¨
    exporter = get_exporter(port=8000)
    
    logger.info("="*80)
    logger.info("ğŸ§ª Prometheus Monitoring Test")
    logger.info("="*80)
    logger.info("")
    logger.info("ğŸ“Š Metrics endpoint: http://localhost:8000/metrics")
    logger.info("ğŸ’š Health check: http://localhost:8000/health")
    logger.info("")
    logger.info("Starting simulation...")
    logger.info("")
    
    # æ¨¡æ‹Ÿäº¤æ˜“å¯¹
    exchanges = ["gate_io", "mexc"]
    symbols = {
        "gate_io": ["VIRTUAL-USDT", "IRON-USDT", "LMTS-USDT"],
        "mexc": ["AUKIUSDT", "IRONUSDT", "SERVUSDT"]
    }
    
    # åˆå§‹åŒ–è¿æ¥çŠ¶æ€
    for exchange in exchanges:
        for symbol in symbols[exchange]:
            metrics.set_connection_status(exchange, symbol, 1)  # å·²è¿æ¥
    
    try:
        iteration = 0
        while True:
            iteration += 1
            logger.info(f"--- Iteration {iteration} ---")
            
            for exchange in exchanges:
                for symbol in symbols[exchange]:
                    # æ¨¡æ‹Ÿæ¥æ”¶æ¶ˆæ¯
                    num_messages = random.randint(50, 200)
                    for _ in range(num_messages):
                        message_type = random.choice(["update", "snapshot"])
                        metrics.increment_messages_received(exchange, symbol, message_type)
                    
                    # æ¨¡æ‹Ÿå¤„ç†æˆåŠŸ
                    success_count = int(num_messages * 0.98)  # 98%æˆåŠŸç‡
                    for _ in range(success_count):
                        metrics.increment_messages_processed(exchange, symbol)
                        
                        # æ¨¡æ‹Ÿå¤„ç†å»¶è¿Ÿ
                        latency = random.uniform(0.001, 0.05)
                        metrics.observe_processing_latency(exchange, symbol, latency)
                    
                    # æ¨¡æ‹Ÿå¤„ç†å¤±è´¥
                    failed_count = num_messages - success_count
                    if failed_count > 0:
                        error_types = ["parse_error", "validation_error", "timeout"]
                        for _ in range(failed_count):
                            error_type = random.choice(error_types)
                            metrics.increment_messages_failed(exchange, symbol, error_type)
                    
                    # æ¨¡æ‹Ÿåºåˆ—å·é—´éš™
                    if random.random() < 0.1:  # 10%æ¦‚ç‡å‡ºç°é—´éš™
                        gap_size = random.choice([5, 15, 60, 120])
                        metrics.record_sequence_gap(exchange, symbol, gap_size)
                    
                    # æ¨¡æ‹Ÿç¼“å†²åŒºå¤§å°
                    buffer_size = random.randint(50, 150)
                    metrics.set_buffer_size(exchange, symbol, buffer_size)
                    
                    # æ¨¡æ‹Ÿå†™å…¥tick
                    if buffer_size > 100 or (iteration % 10 == 0):
                        ticks_count = buffer_size
                        metrics.increment_ticks_written(exchange, symbol, ticks_count)
                        
                        # æ¨¡æ‹Ÿæ–‡ä»¶å†™å…¥
                        if random.random() < 0.3:  # 30%æ¦‚ç‡å†™å…¥æ–°æ–‡ä»¶
                            metrics.increment_files_written(exchange, symbol)
                            write_latency = random.uniform(0.1, 1.0)
                            metrics.observe_file_write_latency(exchange, symbol, write_latency)
                    
                    # æ›´æ–°æœ€åæ¶ˆæ¯æ—¶é—´
                    metrics.update_last_message_time(exchange, symbol, time.time())
                    
                    # æ›´æ–°æ•°æ®æ–°é²œåº¦
                    freshness = random.uniform(0, 5)
                    metrics.update_data_freshness(exchange, symbol, freshness)
                    
                    # å¶å°”æ¨¡æ‹Ÿè¿æ¥é—®é¢˜
                    if random.random() < 0.01:  # 1%æ¦‚ç‡æ–­å¼€
                        logger.warning(f"âš ï¸  Simulating disconnection: {exchange} {symbol}")
                        metrics.set_connection_status(exchange, symbol, 0)
                        metrics.record_disconnection(exchange, symbol, "connection_lost")
                        time.sleep(2)
                        
                        # é‡è¿
                        logger.info(f"ğŸ”„ Reconnecting: {exchange} {symbol}")
                        metrics.set_connection_status(exchange, symbol, 2)
                        metrics.record_reconnection(exchange, symbol)
                        time.sleep(1)
                        
                        metrics.set_connection_status(exchange, symbol, 1)
            
            # æ¨¡æ‹Ÿç£ç›˜ä½¿ç”¨é‡
            for exchange in exchanges:
                disk_usage = random.randint(9 * 1024 * 1024, 12 * 1024 * 1024)  # 9-12 MB
                metrics.update_disk_usage(exchange, disk_usage)
            
            logger.info(f"âœ… Simulated metrics for {len(exchanges)} exchanges")
            logger.info(f"   Check metrics at: http://localhost:8000/metrics")
            logger.info("")
            
            # ç­‰å¾…ä¸‹ä¸€è½®
            time.sleep(5)
    
    except KeyboardInterrupt:
        logger.info("\n\nâ¸ï¸  Simulation stopped")
        logger.info("Metrics endpoint remains available for a few more seconds...")


if __name__ == "__main__":
    try:
        simulate_data_collection()
    except Exception as e:
        logger.error(f"Test failed: {e}", exc_info=True)

