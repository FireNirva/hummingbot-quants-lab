#!/usr/bin/env python3
"""
CEX-DEX ä»·å·®åˆ†æå·¥å…·

æ”¯æŒä¸¤ç§åˆ†ææ¨¡å¼ï¼š
1. è¿ç»­æ—¶é—´è½´ï¼ˆè¡¥å…¨åï¼‰ï¼šå®è§‚è§‚æµ‹ä»·å·®è¶‹åŠ¿
2. äº‹ä»¶æ—¶é—´ï¼ˆä»…å®é™…äº¤æ˜“ï¼‰ï¼šè¯„ä¼°çœŸå®å¯å¥—åˆ©æ€§
"""
import sys
from pathlib import Path

import numpy as np
import pandas as pd
import yaml

# Add project root to path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.data_paths import data_paths
from core.utils.dex_data_fill import (
    align_dex_to_cex,
    create_spread_dataframe,
    get_spread_statistics
)


def analyze_pair_spread(trading_pair: str, interval: str = "1m", volume_threshold: float = 100.0, connector: str = "gate_io", network: str = "base"):
    """
    åˆ†æå•ä¸ªäº¤æ˜“å¯¹çš„ CEX-DEX ä»·å·®ã€‚
    
    Args:
        trading_pair: äº¤æ˜“å¯¹åç§°ï¼Œå¦‚ "AERO-USDT"
        interval: æ—¶é—´é—´éš”
        volume_threshold: DEX æˆäº¤é‡é˜ˆå€¼ï¼ˆç”¨äºå¯æ‰§è¡Œæ€§è¿‡æ»¤ï¼‰
        connector: CEX è¿æ¥å™¨åç§°ï¼ˆå¦‚ "gate_io", "mexc"ï¼‰
        network: DEX ç½‘ç»œåç§°ï¼ˆå¦‚ "base"ï¼‰
    """
    print("\n" + "="*80)
    print(f"ğŸ“Š CEX-DEX ä»·å·®åˆ†æ: {trading_pair} ({interval})")
    print(f"   CEX: {connector} | DEX: {network}")
    print("="*80)
    print()
    
    # 1. åŠ è½½æ•°æ®
    print("ğŸ“ åŠ è½½æ•°æ®...")
    cex_file = data_paths.candles_dir / f"{connector}|{trading_pair}|{interval}.parquet"
    dex_file = data_paths.candles_dir / f"geckoterminal_{network}|{trading_pair}|{interval}.parquet"
    
    if not cex_file.exists():
        print(f"âŒ CEX æ•°æ®ä¸å­˜åœ¨: {cex_file.name}")
        return False
    
    if not dex_file.exists():
        print(f"âŒ DEX æ•°æ®ä¸å­˜åœ¨: {dex_file.name}")
        return False
    
    cex_df = pd.read_parquet(cex_file)
    dex_df_raw = pd.read_parquet(dex_file)
    
    print(f"âœ… CEX æ•°æ®: {len(cex_df):,} æ ¹Kçº¿")
    print(f"âœ… DEX æ•°æ®ï¼ˆåŸå§‹ï¼‰: {len(dex_df_raw):,} æ ¹Kçº¿")
    print(f"   è¦†ç›–ç‡: {len(dex_df_raw)/len(cex_df)*100:.2f}%")
    print()
    
    # 2. è¡¥å…¨ DEX æ•°æ®
    print("ğŸ”§ è¡¥å…¨ DEX æ•°æ®...")
    dex_df_filled = align_dex_to_cex(cex_df, dex_df_raw, interval)
    
    n_filled = dex_df_filled['is_filled'].sum()
    print(f"âœ… è¡¥å…¨å®Œæˆ: æ–°å¢ {n_filled:,} æ ¹èœ¡çƒ›")
    print()
    
    # 3. åˆ›å»ºä»·å·®æ•°æ®
    print("ğŸ“ˆ è®¡ç®—ä»·å·®...")
    spread_df = create_spread_dataframe(cex_df, dex_df_filled)
    
    # åº”ç”¨æˆäº¤é‡è¿‡æ»¤
    spread_df['meets_volume_threshold'] = spread_df['dex_volume'] >= volume_threshold
    
    print(f"âœ… ä»·å·®æ•°æ®: {len(spread_df):,} ä¸ªæ—¶é—´ç‚¹")
    print()
    
    # 4. ç»Ÿè®¡åˆ†æ - æ¨¡å¼ 1ï¼šè¿ç»­æ—¶é—´è½´ï¼ˆå«è¡¥å…¨ï¼‰
    print("="*80)
    print("ğŸ“Š æ¨¡å¼ 1: è¿ç»­æ—¶é—´è½´åˆ†æï¼ˆå«è¡¥å…¨æ•°æ®ï¼‰")
    print("="*80)
    print("ğŸ’¡ ç”¨é€”: å®è§‚è§‚æµ‹ä»·å·®è¶‹åŠ¿ï¼Œäº†è§£åä¹‰å¥—åˆ©ç©ºé—´")
    print()
    
    stats_full = get_spread_statistics(spread_df, include_filled=True)
    
    print(f"æ•°æ®ç‚¹æ•°: {stats_full['total_points']:,}")
    print(f"å¹³å‡ä»·å·®: {stats_full['mean_spread_pct']:+.4f}%")
    print(f"ä¸­ä½ä»·å·®: {stats_full['median_spread_pct']:+.4f}%")
    print(f"æ ‡å‡†å·®: {stats_full['std_spread_pct']:.4f}%")
    print(f"ä»·å·®èŒƒå›´: [{stats_full['min_spread_pct']:+.4f}%, {stats_full['max_spread_pct']:+.4f}%]")
    print()
    
    arb_full = stats_full['arb_opportunities']
    total_full = sum(arb_full.values())
    
    print("åä¹‰å¥—åˆ©æœºä¼šï¼ˆä»·å·® > 0.5%ï¼‰:")
    print(f"  CEXâ†’DEX: {arb_full['cex_to_dex']:,} æ¬¡ ({arb_full['cex_to_dex']/total_full*100:.2f}%)")
    print("    â†’ CEX ä¹°å…¥ï¼ŒDEX å–å‡º")
    print(f"  DEXâ†’CEX: {arb_full['dex_to_cex']:,} æ¬¡ ({arb_full['dex_to_cex']/total_full*100:.2f}%)")
    print("    â†’ DEX ä¹°å…¥ï¼ŒCEX å–å‡º")
    print(f"  å¹³è¡¡åŒº: {arb_full['neutral']:,} æ¬¡ ({arb_full['neutral']/total_full*100:.2f}%)")
    print()
    
    # 5. ç»Ÿè®¡åˆ†æ - æ¨¡å¼ 2ï¼šäº‹ä»¶æ—¶é—´ï¼ˆä»…å®é™…äº¤æ˜“ï¼‰
    print("="*80)
    print("ğŸ“Š æ¨¡å¼ 2: äº‹ä»¶æ—¶é—´åˆ†æï¼ˆä»… DEX å®é™…äº¤æ˜“ï¼‰")
    print("="*80)
    print("ğŸ’¡ ç”¨é€”: è¯„ä¼°çœŸå®å¯æ‰§è¡Œçš„å¥—åˆ©æœºä¼š")
    print()
    
    stats_real = get_spread_statistics(spread_df, include_filled=False)
    
    print(f"æ•°æ®ç‚¹æ•°: {stats_real['total_points']:,} (å®é™…äº¤æ˜“)")
    print(f"å¹³å‡ä»·å·®: {stats_real['mean_spread_pct']:+.4f}%")
    print(f"ä¸­ä½ä»·å·®: {stats_real['median_spread_pct']:+.4f}%")
    print(f"æ ‡å‡†å·®: {stats_real['std_spread_pct']:.4f}%")
    print(f"ä»·å·®èŒƒå›´: [{stats_real['min_spread_pct']:+.4f}%, {stats_real['max_spread_pct']:+.4f}%]")
    print()
    
    arb_real = stats_real['arb_opportunities']
    total_real = sum(arb_real.values())
    
    print("å¯æ‰§è¡Œå¥—åˆ©æœºä¼šï¼ˆDEX æœ‰æˆäº¤ + ä»·å·® > 0.5%ï¼‰:")
    print(f"  CEXâ†’DEX: {arb_real['cex_to_dex']:,} æ¬¡ ({arb_real['cex_to_dex']/total_real*100:.2f}%)")
    print(f"  DEXâ†’CEX: {arb_real['dex_to_cex']:,} æ¬¡ ({arb_real['dex_to_cex']/total_real*100:.2f}%)")
    print(f"  å¹³è¡¡åŒº: {arb_real['neutral']:,} æ¬¡ ({arb_real['neutral']/total_real*100:.2f}%)")
    print()
    
    # 6. æˆäº¤é‡è¿‡æ»¤åˆ†æ
    print("="*80)
    print(f"ğŸ“Š æˆäº¤é‡è¿‡æ»¤åˆ†æï¼ˆé˜ˆå€¼: ${volume_threshold:.0f}ï¼‰")
    print("="*80)
    print()
    
    volume_filtered = spread_df[
        (~spread_df['dex_is_filled']) & 
        (spread_df['meets_volume_threshold'])
    ]
    
    print(f"æ»¡è¶³æˆäº¤é‡é˜ˆå€¼: {len(volume_filtered):,} / {stats_real['total_points']:,} æ¬¡")
    print(f"  ({len(volume_filtered)/stats_real['total_points']*100:.2f}%)")
    print()
    
    if len(volume_filtered) > 0:
        arb_cex_to_dex = len(volume_filtered[volume_filtered['arb_direction'] == 'cex_to_dex'])
        arb_dex_to_cex = len(volume_filtered[volume_filtered['arb_direction'] == 'dex_to_cex'])
        
        print("é«˜æµåŠ¨æ€§å¥—åˆ©æœºä¼š:")
        print(f"  CEXâ†’DEX: {arb_cex_to_dex:,} æ¬¡")
        print(f"  DEXâ†’CEX: {arb_dex_to_cex:,} æ¬¡")
        print()
    
    # 7. æ—¶é—´åˆ†å¸ƒåˆ†æ
    print("="*80)
    print("ğŸ“Š æ—¶é—´åˆ†å¸ƒåˆ†æ")
    print("="*80)
    print()
    
    # æŒ‰å°æ—¶ç»Ÿè®¡
    spread_df['hour'] = spread_df.index.hour
    real_trades = spread_df[~spread_df['dex_is_filled']]
    
    hourly_stats = real_trades.groupby('hour').agg({
        'dex_volume': 'sum',
        'price_diff_pct': 'mean'
    }).round(2)
    
    print("æ¯å°æ—¶ç»Ÿè®¡ï¼ˆä»…å®é™…äº¤æ˜“ï¼‰:")
    print(f"  æœ€æ´»è·ƒæ—¶æ®µ: {hourly_stats['dex_volume'].idxmax()}:00 UTC")
    print(f"  æœ€å¤§æˆäº¤é‡: ${hourly_stats['dex_volume'].max():,.0f}")
    print(f"  å¹³å‡ä»·å·®æœ€å¤§: {hourly_stats['price_diff_pct'].abs().idxmax()}:00 UTC "
          f"({hourly_stats['price_diff_pct'].abs().max():+.4f}%)")
    print()
    
    # 8. ä¿å­˜åˆ†æç»“æœ
    print("ğŸ’¾ ä¿å­˜åˆ†æç»“æœ...")
    output_file = data_paths.spread_analysis_dir / f"spread_analysis_{trading_pair}_{interval}.parquet"
    spread_df.to_parquet(output_file)
    print(f"âœ… å·²ä¿å­˜åˆ°: {output_file}")
    print()
    
    # 9. å¯è§†åŒ–å»ºè®®
    print("="*80)
    print("ğŸ“ˆ å¯è§†åŒ–å»ºè®®")
    print("="*80)
    print()
    print("å»ºè®®åˆ›å»ºä»¥ä¸‹å›¾è¡¨:")
    print("  1. ä»·å·®æ—¶åºå›¾ï¼ˆåŒæ›²çº¿ï¼‰:")
    print("     - æ›²çº¿1: è¿ç»­ä»·å·®ï¼ˆå«è¡¥å…¨ï¼Œç°è‰²è™šçº¿ï¼‰")
    print("     - æ›²çº¿2: å®é™…äº¤æ˜“ä»·å·®ï¼ˆè“è‰²å®çº¿ï¼‰")
    print("     - å åŠ : æˆäº¤é‡æŸ±çŠ¶å›¾ï¼ˆåº•éƒ¨ï¼‰")
    print()
    print("  2. ä»·å·®åˆ†å¸ƒç›´æ–¹å›¾:")
    print("     - å¯¹æ¯”è¡¥å…¨æ•°æ® vs å®é™…äº¤æ˜“æ•°æ®")
    print("     - æ ‡æ³¨å¥—åˆ©é˜ˆå€¼ (Â±0.5%)")
    print()
    print("  3. æµåŠ¨æ€§çƒ­åŠ›å›¾:")
    print("     - Xè½´: æ—¶é—´, Yè½´: ä»·å·®åŒºé—´")
    print("     - é¢œè‰²: DEX æˆäº¤é‡")
    print()
    
    return True


def load_trading_pairs_from_config(config_file: str = "config/base_ecosystem_downloader_full.yml"):
    """
    ä»é…ç½®æ–‡ä»¶ä¸­åŠ è½½äº¤æ˜“å¯¹åˆ—è¡¨ã€‚
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ç›®å½•ï¼‰
    
    Returns:
        äº¤æ˜“å¯¹åˆ—è¡¨
    """
    config_path = project_root / config_file
    
    if not config_path.exists():
        print(f"âš ï¸  é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_path}")
        return []
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        
        # ä» YAML ä¸­æå– trading_pairs
        tasks = config.get('tasks', {})
        for task_name, task_config in tasks.items():
            task_data = task_config.get('config', {})
            if 'trading_pairs' in task_data:
                pairs = task_data['trading_pairs']
                print(f"âœ… ä»é…ç½®æ–‡ä»¶åŠ è½½äº† {len(pairs)} ä¸ªäº¤æ˜“å¯¹")
                return pairs
        
        print("âš ï¸  é…ç½®æ–‡ä»¶ä¸­æœªæ‰¾åˆ° trading_pairs")
        return []
    
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return []


def get_volume_multiplier(volume: float) -> float:
    """
    æˆäº¤é‡è¯„åˆ†ç³»æ•°ï¼ˆå€’Uå‹æ›²çº¿ï¼‰
    
    å¤ªä½å’Œå¤ªé«˜çš„æˆäº¤é‡éƒ½ä¼šé™ä½è¯„åˆ†ï¼š
    - < $100K: æ— æ³•å¥—åˆ©ï¼Œè¯„åˆ†å½’é›¶ Ã—0
    - $100K - $500K: æµåŠ¨æ€§ä¸è¶³ï¼Œè¯„åˆ†Ã—0.5-0.8
    - $500K - $10M: æœ€ä½³åŒºé—´ï¼Œè¯„åˆ†Ã—1.0 âœ…
    - $10M - $50M: ç«äº‰åŠ å‰§ï¼Œè¯„åˆ†Ã—0.8-0.5
    - > $50M: æåº¦ç«äº‰ï¼Œè¯„åˆ†Ã—0.3
    
    Args:
        volume: æ€»æˆäº¤é‡ï¼ˆUSDï¼‰
    
    Returns:
        è¯„åˆ†ç³»æ•° (0.0 - 1.0)
    """
    if volume < 100_000:
        # æä½æµåŠ¨æ€§ï¼š< $100K
        # æ— æ³•å¥—åˆ©ï¼Œç›´æ¥å½’é›¶
        return 0.0
    
    elif volume < 500_000:
        # ä½æµåŠ¨æ€§ï¼š$100K - $500K
        # çº¿æ€§å¢åŠ  0.5 â†’ 0.8
        return 0.5 + (volume - 100_000) / 400_000 * 0.3
    
    elif volume <= 10_000_000:
        # æœ€ä½³åŒºé—´ï¼š$500K - $10M
        # æœ€é«˜è¯„åˆ†Ã—1.0
        return 1.0
    
    elif volume <= 50_000_000:
        # é«˜æµåŠ¨æ€§ï¼š$10M - $50M
        # çº¿æ€§é™ä½ 0.8 â†’ 0.5
        return 0.8 - (volume - 10_000_000) / 40_000_000 * 0.3
    
    else:
        # æé«˜æµåŠ¨æ€§ï¼š> $50M
        # ç«äº‰éå¸¸æ¿€çƒˆï¼Œè¯„åˆ†Ã—0.3
        return 0.3


def compare_multiple_pairs(config_file: str = None, interval: str = "1m", connector: str = "gate_io", network: str = "base"):
    """
    å¯¹æ¯”å¤šä¸ªäº¤æ˜“å¯¹çš„å¥—åˆ©æ½œåŠ›ã€‚
    
    Args:
        config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰ï¼Œå¦‚ä¸æä¾›åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        interval: æ—¶é—´é—´éš”ï¼ˆå¦‚ "1m", "5m"ï¼‰
        connector: CEX è¿æ¥å™¨åç§°ï¼ˆå¦‚ "gate_io", "mexc"ï¼‰
        network: DEX ç½‘ç»œåç§°ï¼ˆå¦‚ "base"ï¼‰
    """
    print("\n" + "="*80)
    print(f"ğŸ“Š å¤šäº¤æ˜“å¯¹å¥—åˆ©æ½œåŠ›å¯¹æ¯” ({interval})")
    print(f"   CEX: {connector} | DEX: {network}")
    print("="*80)
    print()
    
    # ä»é…ç½®æ–‡ä»¶åŠ è½½äº¤æ˜“å¯¹
    if config_file:
        pairs = load_trading_pairs_from_config(config_file)
    else:
        pairs = load_trading_pairs_from_config()
    
    if not pairs:
        print("âŒ æœªæ‰¾åˆ°äº¤æ˜“å¯¹åˆ—è¡¨ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨")
        pairs = ["AERO-USDT", "VIRTUAL-USDT", "BRETT-USDT", "GPS-USDT"]
    
    print(f"ğŸ“‹ å°†åˆ†æ {len(pairs)} ä¸ªäº¤æ˜“å¯¹ (æ—¶é—´é—´éš”: {interval})")
    print()
    
    results = []
    
    for pair in pairs:
        cex_file = data_paths.candles_dir / f"{connector}|{pair}|{interval}.parquet"
        dex_file = data_paths.candles_dir / f"geckoterminal_{network}|{pair}|{interval}.parquet"
        
        if not cex_file.exists() or not dex_file.exists():
            continue
        
        cex_df = pd.read_parquet(cex_file)
        dex_df_raw = pd.read_parquet(dex_file)
        dex_df_filled = align_dex_to_cex(cex_df, dex_df_raw, interval)
        spread_df = create_spread_dataframe(cex_df, dex_df_filled)
        
        # ç»Ÿè®¡
        real_trades = spread_df[~spread_df['dex_is_filled']]
        executable = real_trades[real_trades['is_executable']]
        
        results.append({
            'pair': pair,
            'dex_coverage': len(dex_df_raw) / len(cex_df) * 100,
            'avg_spread': real_trades['price_diff_pct'].abs().mean(),
            'executable_ops': len(executable[executable['arb_direction'] != 'neutral']),
            'total_volume': real_trades['dex_volume'].sum()
        })
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆç»“æœ
    if not results:
        print("âŒ é”™è¯¯ï¼šæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„äº¤æ˜“å¯¹æ•°æ®")
        print()
        print("å¯èƒ½çš„åŸå› ï¼š")
        print("  1. DEX æ•°æ®è¿˜æœªä¸‹è½½")
        print("  2. CEX æ•°æ®æ–‡ä»¶å‘½åæ ¼å¼ä¸åŒ¹é…")
        print("  3. äº¤æ˜“å¯¹é…ç½®æœ‰è¯¯")
        print()
        print("ğŸ“‹ é¢„æœŸæ–‡ä»¶æ ¼å¼ï¼š")
        print(f"   CEX: {connector}|PAIR-USDT|{interval}.parquet")
        print(f"   DEX: geckoterminal_{network}|PAIR-USDT|{interval}.parquet")
        return
    
    # æ˜¾ç¤ºå¯¹æ¯”è¡¨æ ¼
    df_results = pd.DataFrame(results)
    
    print("äº¤æ˜“å¯¹å¯¹æ¯”:")
    print("-"*80)
    for _, row in df_results.iterrows():
        # å¤„ç† NaN å€¼
        dex_coverage = row['dex_coverage'] if not pd.isna(row['dex_coverage']) else 0
        avg_spread = row['avg_spread'] if not pd.isna(row['avg_spread']) else 0
        executable_ops = row['executable_ops'] if not pd.isna(row['executable_ops']) else 0
        total_volume = row['total_volume'] if not pd.isna(row['total_volume']) else 0
        
        # å¦‚æœä»·å·®ä¸º 0 æˆ– NaNï¼Œæ˜¾ç¤ºä¸º "N/A"
        if pd.isna(row['avg_spread']) or row['avg_spread'] == 0:
            spread_str = "   N/A"
        else:
            spread_str = f"{avg_spread:5.2f}%"
        
        print(f"{row['pair']:15s} | "
              f"è¦†ç›–ç‡: {dex_coverage:5.1f}% | "
              f"å¹³å‡ä»·å·®: {spread_str} | "
              f"å¯æ‰§è¡Œæœºä¼š: {executable_ops:5.0f} æ¬¡ | "
              f"æ€»æˆäº¤é‡: ${total_volume:,.0f}")
    print()
    
    # æ¨èæ’åºï¼ˆæœ€ç»ˆä¼˜åŒ–ç‰ˆ + æˆäº¤é‡é˜ˆå€¼ï¼‰
    print("ğŸ’¡ æ¨èæ’åºï¼ˆç»¼åˆè¯„åˆ† - æœ€ç»ˆä¼˜åŒ–ç‰ˆ V4ï¼‰:")
    print("   æ ¸å¿ƒç†å¿µ: æŠ“ä½æœ¬è´¨ + æˆäº¤é‡å€’Uå‹ä¼˜åŒ–")
    print("   è¯„åˆ†å…¬å¼: score = (ä»·å·®Ã—10 + æœºä¼šæ•°/10) Ã— æˆäº¤é‡ç³»æ•°")
    print()
    print("   ğŸ¯ æ ¸å¿ƒè¦ç´ :")
    print("      1. ä»·å·® â†’ å†³å®šæ¯æ¬¡èƒ½èµšå¤šå°‘ï¼ˆæœ€é‡è¦ï¼ï¼‰")
    print("      2. æœºä¼šæ•° â†’ å†³å®šèƒ½èµšå¤šå°‘æ¬¡ï¼ˆå¾ˆé‡è¦ï¼ï¼‰")
    print("      3. æˆäº¤é‡ç³»æ•° â†’ å€’Uå‹æ›²çº¿ï¼ˆå¤ªä½æˆ–å¤ªé«˜éƒ½é™ä½æ’åï¼‰")
    print()
    print("   ğŸ“Š æˆäº¤é‡é˜ˆå€¼:")
    print("      â€¢ < $100K:       è¯„åˆ†Ã—0 âŒ ï¼ˆæ— æ³•å¥—åˆ©ï¼Œç›´æ¥å½’é›¶ï¼‰")
    print("      â€¢ $100K - $500K: è¯„åˆ†Ã—0.5-0.8 ï¼ˆä½æµåŠ¨æ€§ï¼‰")
    print("      â€¢ $500K - $10M:  è¯„åˆ†Ã—1.0 âœ… ï¼ˆæœ€ä½³åŒºé—´ï¼‰")
    print("      â€¢ $10M - $50M:   è¯„åˆ†Ã—0.8-0.5 ï¼ˆç«äº‰åŠ å‰§ï¼‰")
    print("      â€¢ > $50M:        è¯„åˆ†Ã—0.3 ï¼ˆæåº¦ç«äº‰ï¼‰")
    print()
    
    # æœ€ç»ˆä¼˜åŒ–çš„è¯„åˆ†å…¬å¼ V4ï¼šæ·»åŠ æˆäº¤é‡é˜ˆå€¼
    # score = (ä»·å·® Ã— 10 + æœºä¼šæ•° / 10) Ã— volume_multiplier
    # 
    # æˆäº¤é‡ç³»æ•°ï¼šå€’Uå‹æ›²çº¿
    # - å¤ªä½ï¼ˆ<$100Kï¼‰ï¼šæµåŠ¨æ€§ä¸è¶³ï¼Œæƒ©ç½šÃ—0.3
    # - é€‚ä¸­ï¼ˆ$500K-$10Mï¼‰ï¼šæœ€ä½³åŒºé—´ï¼Œä¿æŒÃ—1.0
    # - å¤ªé«˜ï¼ˆ>$50Mï¼‰ï¼šç«äº‰æ¿€çƒˆï¼Œæƒ©ç½šÃ—0.3
    
    # è®¡ç®—æˆäº¤é‡ç³»æ•°
    df_results['volume_multiplier'] = df_results['total_volume'].apply(get_volume_multiplier)
    
    # åŸºç¡€è¯„åˆ†
    df_results['base_score'] = (
        df_results['avg_spread'] * 10 +      # ä»·å·®ï¼šå†³å®šç›ˆåˆ©ç©ºé—´
        df_results['executable_ops'] / 10     # æœºä¼šæ•°ï¼šå†³å®šäº¤æ˜“é¢‘æ¬¡
    )
    
    # æœ€ç»ˆè¯„åˆ† = åŸºç¡€è¯„åˆ† Ã— æˆäº¤é‡ç³»æ•°
    df_results['score'] = df_results['base_score'] * df_results['volume_multiplier']
    
    # å¤„ç† NaN å€¼ï¼šå¦‚æœè¯„åˆ†æˆ–å…¶ä»–å­—æ®µä¸º NaNï¼ˆé€šå¸¸å› ä¸ºæ•°æ®ä¸è¶³ï¼‰ï¼Œè®¾ç½®ä¸º 0
    df_results = df_results.fillna({
        'avg_spread': 0,
        'executable_ops': 0,
        'base_score': 0,
        'volume_multiplier': 0,
        'score': 0
    })
    
    df_sorted = df_results.sort_values('score', ascending=False)
    
    for i, (_, row) in enumerate(df_sorted.iterrows(), 1):
        # è¯„åˆ†åŒºé—´è°ƒæ•´ä¸ºæ›´åˆç†çš„åˆ»åº¦
        # å¤„ç† NaN æˆ–æ— ç©·å¤§çš„æƒ…å†µ
        score_val = row['score'] if not pd.isna(row['score']) and not np.isinf(row['score']) else 0
        rating = "â­" * min(5, int(score_val / 10))
        
        # æ·»åŠ æµåŠ¨æ€§è­¦å‘Šï¼ˆä»…æç¤ºï¼Œä¸å½±å“è¯„åˆ†ï¼‰
        warnings = []
        if row['total_volume'] < 100_000:  # <$100K
            warnings.append("âŒæ— æ³•å¥—åˆ©")
        if row['dex_coverage'] < 1.0:  # <1%
            warnings.append("âš ï¸æä½è¦†ç›–")
        if pd.isna(row['avg_spread']) or row['avg_spread'] == 0:
            warnings.append("âš ï¸æ•°æ®ä¸è¶³")
        warning_str = f" {' '.join(warnings)}" if warnings else ""
        
        print(f"  {i:2d}. {row['pair']:15s} {rating:10s} (è¯„åˆ†: {score_val:6.1f}){warning_str}")
    
    print()
    
    # æ˜¾ç¤ºè¯„åˆ†ç»„æˆæ˜ç»†ï¼ˆå‰ 5 åï¼‰
    print("ğŸ” è¯„åˆ†æ˜ç»†ï¼ˆå‰ 5 åï¼‰:")
    print("-"*80)
    for i, (_, row) in enumerate(df_sorted.head(5).iterrows(), 1):
        # å¤„ç†å¯èƒ½çš„ NaN å€¼
        avg_spread = row['avg_spread'] if not pd.isna(row['avg_spread']) else 0
        executable_ops = row['executable_ops'] if not pd.isna(row['executable_ops']) else 0
        base_score = row['base_score'] if not pd.isna(row['base_score']) else 0
        volume_mult = row['volume_multiplier'] if not pd.isna(row['volume_multiplier']) else 0
        final_score = row['score'] if not pd.isna(row['score']) else 0
        dex_coverage = row['dex_coverage'] if not pd.isna(row['dex_coverage']) else 0
        
        spread_contrib = avg_spread * 10
        ops_contrib = executable_ops / 10
        
        print(f"{i}. {row['pair']}")
        print(f"   ä»·å·®è´¡çŒ®: {spread_contrib:6.1f}åˆ† (avg_spread={avg_spread:.2f}%)")
        print(f"   æœºä¼šè´¡çŒ®: {ops_contrib:6.1f}åˆ† (executable_ops={executable_ops:.0f}æ¬¡)")
        print(f"   åŸºç¡€è¯„åˆ†: {base_score:6.1f}åˆ†")
        print(f"   æˆäº¤é‡ç³»æ•°: {volume_mult:.2f}x (volume=${row['total_volume']:,.0f})")
        print(f"   æœ€ç»ˆè¯„åˆ†: {final_score:6.1f}åˆ† = {base_score:.1f} Ã— {volume_mult:.2f}")
        print(f"   è¦†ç›–ç‡: {dex_coverage:.1f}%")
        print()


def main():
    """ä¸»å‡½æ•°ã€‚"""
    import argparse
    
    parser = argparse.ArgumentParser(description="CEX-DEX ä»·å·®åˆ†æå·¥å…·")
    parser.add_argument('--pair', type=str, default='AERO-USDT', help='äº¤æ˜“å¯¹åç§°')
    parser.add_argument('--interval', type=str, default='1m', help='æ—¶é—´é—´éš”')
    parser.add_argument('--volume-threshold', type=float, default=100.0, 
                       help='DEX æˆäº¤é‡é˜ˆå€¼ï¼ˆUSDï¼‰')
    parser.add_argument('--compare-all', action='store_true', help='å¯¹æ¯”æ‰€æœ‰äº¤æ˜“å¯¹')
    parser.add_argument('--config', type=str, 
                       default='config/base_ecosystem_downloader_full.yml',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆç”¨äº --compare-allï¼‰')
    parser.add_argument('--connector', type=str, default='gate_io',
                       help='CEX è¿æ¥å™¨åç§°ï¼ˆå¦‚ gate_io, mexcï¼‰')
    parser.add_argument('--network', type=str, default='base',
                       help='DEX ç½‘ç»œåç§°ï¼ˆå¦‚ baseï¼‰')
    
    args = parser.parse_args()
    
    if args.compare_all:
        compare_multiple_pairs(config_file=args.config, interval=args.interval, 
                              connector=args.connector, network=args.network)
    else:
        success = analyze_pair_spread(args.pair, args.interval, args.volume_threshold,
                                     connector=args.connector, network=args.network)
        
        if not success:
            return 1
    
    print("="*80)
    print("âœ… åˆ†æå®Œæˆï¼")
    print("="*80)
    print()
    print("ğŸ“ å…³é”®æ´å¯Ÿ:")
    print("  â€¢ è¿ç»­æ—¶é—´è½´åˆ†æï¼šé€‚åˆå®è§‚è¶‹åŠ¿è§‚æµ‹")
    print("  â€¢ äº‹ä»¶æ—¶é—´åˆ†æï¼šåæ˜ çœŸå®å¯æ‰§è¡Œæœºä¼š")
    print("  â€¢ æˆäº¤é‡è¿‡æ»¤ï¼šç¡®ä¿å¥—åˆ©çš„æµåŠ¨æ€§")
    print("  â€¢ è¡¥å…¨æ•°æ®ï¼ˆis_filled=Trueï¼‰ä¸åº”å‚ä¸å›æµ‹")
    print()
    
    return 0


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)

