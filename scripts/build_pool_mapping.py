#!/usr/bin/env python3
"""
CEXäº¤æ˜“å¯¹åˆ°DEXæ± å­æ˜ å°„æ„å»ºè„šæœ¬

ä½¿ç”¨GeckoTerminal APIä¸ºCEXäº¤æ˜“å¯¹æŸ¥æ‰¾å¯¹åº”çš„DEXé«˜æµåŠ¨æ€§æ± å­ã€‚

ç¤ºä¾‹ç”¨æ³•:
    # è‡ªåŠ¨æ£€æµ‹gate_ioçš„æ‰€æœ‰äº¤æ˜“å¯¹
    python scripts/build_pool_mapping.py --network base --connector gate_io
    
    # æŒ‡å®šç‰¹å®šäº¤æ˜“å¯¹
    python scripts/build_pool_mapping.py --network base --pairs AERO-USDT,BRETT-USDT
    
    # ä¿ç•™top 5æ± å­
    python scripts/build_pool_mapping.py --network base --top-n 5
"""
import argparse
import asyncio
import logging
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°sys.path
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.services.pool_mapping import PoolMappingService
from core.data_paths import data_paths

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def parse_args():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='æ„å»ºCEXäº¤æ˜“å¯¹åˆ°DEXæ± å­çš„æ˜ å°„',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # è‡ªåŠ¨æ£€æµ‹gate_ioçš„æ‰€æœ‰äº¤æ˜“å¯¹
  %(prog)s --network base --connector gate_io
  
  # æŒ‡å®šç‰¹å®šäº¤æ˜“å¯¹
  %(prog)s --network base --pairs AERO-USDT,BRETT-USDT,VIRTUAL-USDT
  
  # ä¿ç•™æ¯ä¸ªäº¤æ˜“å¯¹çš„top 5æ± å­
  %(prog)s --network base --connector gate_io --top-n 5
  
  # è‡ªå®šä¹‰è¾“å‡ºç›®å½•
  %(prog)s --network base --output-dir /custom/path
        """
    )
    
    parser.add_argument(
        '--network',
        type=str,
        default='base',
        help='ç½‘ç»œIDï¼ˆé»˜è®¤: baseï¼‰'
    )
    
    parser.add_argument(
        '--connector',
        type=str,
        default='gate_io',
        help='CEXè¿æ¥å™¨åç§°ï¼ˆé»˜è®¤: gate_ioï¼‰'
    )
    
    parser.add_argument(
        '--candles-dir',
        type=Path,
        default=None,
        help=f'Candlesç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: {data_paths.candles_dir}ï¼‰'
    )
    
    parser.add_argument(
        '--output-dir',
        type=Path,
        default=None,
        help=f'è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: {data_paths.processed_dir}ï¼‰'
    )
    
    parser.add_argument(
        '--top-n',
        type=int,
        default=3,
        help='æ¯ä¸ªäº¤æ˜“å¯¹ä¿ç•™çš„æ± å­æ•°é‡ï¼ˆé»˜è®¤: 3ï¼‰'
    )
    
    parser.add_argument(
        '--pairs',
        type=str,
        default=None,
        help='é€—å·åˆ†éš”çš„äº¤æ˜“å¯¹åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œè¦†ç›–è‡ªåŠ¨æ£€æµ‹ï¼‰ã€‚ä¾‹å¦‚: AERO-USDT,BRETT-USDT'
    )
    
    return parser.parse_args()


async def main():
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    print("="*80)
    print("ğŸ—ºï¸  CEX-DEXæ± å­æ˜ å°„æ„å»ºå·¥å…·")
    print("="*80)
    print()
    
    # æ˜¾ç¤ºé…ç½®
    print("ğŸ“‹ é…ç½®ä¿¡æ¯:")
    print(f"  - ç½‘ç»œ: {args.network}")
    print(f"  - è¿æ¥å™¨: {args.connector}")
    print(f"  - Top N: {args.top_n}")
    
    # ç¡®å®šcandlesç›®å½•
    candles_dir = args.candles_dir if args.candles_dir else data_paths.candles_dir
    print(f"  - Candlesç›®å½•: {candles_dir}")
    print()
    
    # åˆå§‹åŒ–æœåŠ¡
    service = PoolMappingService()
    
    try:
        # 1. è·å–äº¤æ˜“å¯¹åˆ—è¡¨
        if args.pairs:
            # ä»å‘½ä»¤è¡Œå‚æ•°è§£æ
            pairs = [p.strip() for p in args.pairs.split(',')]
            print(f"ğŸ“ ä½¿ç”¨æŒ‡å®šçš„äº¤æ˜“å¯¹: {len(pairs)} ä¸ª")
            for pair in pairs:
                print(f"   - {pair}")
        else:
            # è‡ªåŠ¨æ£€æµ‹
            print(f"ğŸ” ä» {candles_dir} è‡ªåŠ¨æ£€æµ‹äº¤æ˜“å¯¹...")
            pairs = service.parse_trading_pairs_from_candles(candles_dir, args.connector)
            
            if not pairs:
                print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ° {args.connector} çš„äº¤æ˜“å¯¹")
                print(f"   è¯·æ£€æŸ¥ç›®å½•: {candles_dir}")
                return 1
            
            print(f"âœ“ æ£€æµ‹åˆ° {len(pairs)} ä¸ªäº¤æ˜“å¯¹:")
            for pair in pairs[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"   - {pair}")
            if len(pairs) > 10:
                print(f"   ... å’Œå…¶ä»– {len(pairs) - 10} ä¸ªäº¤æ˜“å¯¹")
        
        print()
        
        # 2. æ„å»ºæ˜ å°„
        print(f"ğŸ”„ å¼€å§‹æ„å»ºæ± å­æ˜ å°„ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")
        print(f"   é¢„è®¡è€—æ—¶: ~{len(pairs) * 0.5:.0f}ç§’ ({len(pairs)}ä¸ªäº¤æ˜“å¯¹ Ã— 0.5ç§’/ä¸ª)")
        print()
        
        df, raw_responses = await service.build_mapping(
            pairs, 
            args.network, 
            args.connector, 
            args.top_n
        )
        
        # 3. ä¿å­˜ç»“æœ
        print()
        print("ğŸ’¾ ä¿å­˜ç»“æœ...")
        
        # ä¿å­˜åŸå§‹å“åº”
        service.save_raw_responses(raw_responses, args.network)
        
        # ä¿å­˜æ˜ å°„æ•°æ®
        output_file = service.save_mapping(df, args.network, args.connector)
        
        # 4. ç»Ÿè®¡ä¿¡æ¯
        print()
        print("="*80)
        print("ğŸ“Š ç»Ÿè®¡æ‘˜è¦")
        print("="*80)
        
        pools_found = len(df)
        pairs_with_pools = df['trading_pair'].nunique() if not df.empty else 0
        pairs_failed = len(pairs) - pairs_with_pools
        
        print(f"  âœ“ å¤„ç†äº¤æ˜“å¯¹: {len(pairs)} ä¸ª")
        print(f"  âœ“ æˆåŠŸæ˜ å°„: {pairs_with_pools} ä¸ª")
        print(f"  âœ— å¤±è´¥/æ— ç»“æœ: {pairs_failed} ä¸ª")
        print(f"  âœ“ æ‰¾åˆ°æ± å­: {pools_found} ä¸ª")
        print()
        
        # æ˜¾ç¤ºå¤±è´¥çš„äº¤æ˜“å¯¹
        if pairs_failed > 0:
            failed_pairs = set(pairs) - set(df['trading_pair'].unique() if not df.empty else [])
            print("âš ï¸  æœªæ‰¾åˆ°æ± å­çš„äº¤æ˜“å¯¹:")
            for pair in sorted(failed_pairs):
                error_info = raw_responses.get(pair, {})
                if 'error' in error_info:
                    print(f"   - {pair} (é”™è¯¯: {error_info['error']})")
                else:
                    print(f"   - {pair} (æ— æœç´¢ç»“æœ)")
            print()
        
        # æ˜¾ç¤ºè¾“å‡ºæ–‡ä»¶ä½ç½®
        print("ğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"  - åŸå§‹JSON: {data_paths.raw_dir / 'geckoterminal' / 'search_pools' / args.network}/")
        print(f"  - æ˜ å°„æ•°æ®: {output_file}")
        print()
        
        # æ˜¾ç¤ºtopæ± å­ç¤ºä¾‹
        if not df.empty:
            print("ğŸŠ ç¤ºä¾‹æ± å­ï¼ˆæŒ‰æµåŠ¨æ€§æ’åºï¼‰:")
            print()
            
            # è·å–å‰3ä¸ªæœ‰æ± å­çš„äº¤æ˜“å¯¹
            sample_pairs = df.groupby('trading_pair')['reserve_usd'].max().nlargest(3).index
            
            for pair in sample_pairs:
                pair_data = df[df['trading_pair'] == pair].sort_values('rank')
                top_pool = pair_data.iloc[0]
                
                print(f"  {pair}:")
                print(f"    åœ°å€: {top_pool['pool_address'][:10]}...")
                print(f"    DEX: {top_pool['dex_id']}")
                print(f"    æµåŠ¨æ€§: ${top_pool['reserve_usd']:,.0f}")
                print(f"    24häº¤æ˜“é‡: ${top_pool['volume_usd_h24']:,.0f}")
                print()
        
        print("="*80)
        print("âœ… å®Œæˆï¼")
        print("="*80)
        
        return 0
        
    except KeyboardInterrupt:
        print()
        print("âš ï¸  ç”¨æˆ·ä¸­æ–­")
        return 130
    except Exception as e:
        print()
        print(f"âŒ é”™è¯¯: {e}")
        logger.exception("Error during mapping")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)

